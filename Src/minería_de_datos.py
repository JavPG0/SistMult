# -*- coding: utf-8 -*-
"""Minería de Datos.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1V6W4SbS2wPD3mFLvchxtvIL2ww7-S94C

# DATA MINING - Lab Project

## Importaciones
"""

!pip install kagglehub[pandas-datasets]
!pip install https://github.com/pandas-profiling/pandas-profiling/archive/master.zip
!pip install pandas-profiling
!pip install ydata-profiling
!pip install -q rapidfuzz
!pip install unidecode

import pandas as pd
import kagglehub
from kagglehub import KaggleDatasetAdapter
from ydata_profiling import ProfileReport
import pandas as pd
from rapidfuzz import process, fuzz
import unidecode
import re
from sklearn import preprocessing
from sklearn.preprocessing import MinMaxScaler
from sklearn.impute import KNNImputer

"""# recopilación de datos"""

df_emotion = kagglehub.load_dataset(
  KaggleDatasetAdapter.PANDAS,
  "cakiki/muse-the-musical-sentiment-dataset",
  "muse_v3.csv",
)

df_emotion.to_csv('Track Emotions.csv', index=False)

df_spotify_youtube = kagglehub.load_dataset(
  KaggleDatasetAdapter.PANDAS,
  "salvatorerastelli/spotify-and-youtube",
  "Spotify_Youtube.csv")

df_genres = kagglehub.load_dataset(
  KaggleDatasetAdapter.PANDAS,
  "thedevastator/spotify-tracks-genre-dataset",
  "train.csv")

"""## Preprocesamiento"""

# Elimina las filas con valores faltantes del DataFrame
df_spotify_youtube = df_spotify_youtube.dropna()

df_spotify_youtube.isnull().values.any()

# Cambia el nombre de la columna "Unnamed: 0" a "ID"
# Establece la columna "ID" como índice del DataFrame
df_spotify_youtube = df_spotify_youtube.rename(columns={"Unnamed: 0": "ID"})
df_spotify_youtube = df_spotify_youtube.set_index("ID")

df_spotify_youtube.shape

df_spotify_youtube.head()

df_genres.shape

df_genres.isnull().values.any()

# Elimina las filas con valores faltantes del DataFrame
df_genres = df_genres.dropna()

df_genres.isnull().values.any()

# Cambia el nombre de la columna "Unnamed: 0" a "ID"
# Elimina la columna "ID" del DataFrame
# Establece la columna "track_id" como índice del DataFrame
df_genres = df_genres.rename(columns={"Unnamed: 0": "ID"})
df_genres = df_genres.drop(columns={"ID"})
df_genres = df_genres.set_index("track_id")

df_genres.head()

df_genres.shape

# Crea un conjunto con los nombres de canciones del DataFrame df_spotify_youtube en minúsculas y sin espacios extra
original = set(df_spotify_youtube['Track'].str.lower().str.strip())
# Crea un conjunto con los nombres de canciones del DataFrame df_genres en minúsculas y sin espacios extra
comparacion = set(df_genres['track_name'].str.lower().str.strip())

# Obtiene los nombres de canciones que aparecen en ambos conjuntos
# Muestra la cantidad de canciones que coinciden entre los dos DataFrames
coincidentes = original.intersection(comparacion)
print(f"Número de artistas coincidentes: {len(coincidentes)}")

# Calcula el porcentaje de coincidencias respecto al total de canciones del DataFrame original
# Muestra el porcentaje de canciones coincidentes con dos decimales
porcentaje = len(coincidentes) / len(original) * 100
print(f"Porcentaje de artistas coincidentes: {porcentaje:.2f}%")

print("Columnas del dataset base (Spotify + YouTube):")
print(df_spotify_youtube.columns.tolist(), "\n")

print("Columnas del dataset de géneros:")
print(df_genres.columns.tolist(),"\n")

print("Columnas del dataset de emociones")
print(df_emotion.columns.tolist())

"""# Explicación del Proceso de Normalización y Coincidencia de Datos

Al trabajar con los datasets de Spotify + YouTube, géneros y emociones, uno de los desafíos principales fue lograr una correspondencia confiable entre los nombres de artistas y canciones de diferentes fuentes. El proceso evolucionó a través de varias etapas, optimizando tanto la precisión como el rendimiento.

## 1. Coincidencia exacta inicial
En un primer enfoque, se intentó realizar una **coincidencia exacta** entre los nombres de artistas y canciones concatenados (`artist - track`). Para ello, se normalizaron los nombres convirtiéndolos a minúsculas y eliminando espacios iniciales y finales.  

**Resultados:**  
- La cobertura fue extremadamente baja; de las ~19.000 canciones del dataset principal, se pudieron asignar géneros a menos de un 25% y emociones a menos del 10%.  
- Esto se debía a pequeñas diferencias en la escritura de los nombres, presencia de acentos, paréntesis, abreviaciones (`feat.`, `ft.`) y errores tipográficos.

## 2. Inclusión de coincidencia difusa (Fuzzy Matching)
Para mejorar la convergencia, se implementó **fuzzy matching** usando la librería `rapidfuzz`. Este método calcula la similitud entre cadenas y permite encontrar coincidencias aproximadas.  

**Resultados:**  
- La cobertura mejoró significativamente respecto a la coincidencia exacta.  
- Sin embargo, con el umbral inicial del 80%, todavía muchas coincidencias válidas no se encontraban debido a ligeras diferencias en los nombres de artistas o canciones.

## 3. Ajuste del umbral de similitud
Para aumentar aún más la cobertura, se redujo el umbral de coincidencia de 80% a **60%**, lo que permitió captar variaciones más amplias sin perder precisión.  

**Resultados:**  
- La cantidad de filas con géneros y emociones asignados aumentó considerablemente.  
- Este cambio mostró un equilibrio adecuado entre **exactitud y cobertura**, capturando muchas coincidencias que antes se perdían.

## 4. Intentos de métodos más complejos
Se exploraron métodos más sofisticados, como separar el matching por artista y canción por separado, crear vistas optimizadas y aplicar coincidencias por bloques más inteligentes.  

**Limitaciones:**  
- Aunque estos métodos podrían aumentar la cobertura de manera incremental, su tiempo de ejecución era demasiado elevado para datasets de gran tamaño (~19.000 filas frente a 100.000+ filas en los datasets de referencia).  
- Esto generaba problemas de escalabilidad y de eficiencia en Google Colab.

## 5. Normalización avanzada con Unicode
Finalmente, para mejorar aún más la calidad de las coincidencias, se implementó una normalización más completa:  

- Eliminación de acentos y caracteres especiales mediante `unidecode`.  
- Eliminación de contenido entre paréntesis, por ejemplo, versiones, remixes o notas adicionales en los títulos.  
- Uniformización de abreviaciones de colaboraciones (`feat.`, `ft.` → `feat`).  
- Estandarización de guiones, espacios y caracteres especiales (`&` → `and`).  

**Impacto:**  
- Esta normalización permitió que muchas coincidencias que antes fallaban por diferencias tipográficas o de codificación se pudieran encontrar correctamente.  
- Combinada con el umbral reducido del 60% y el fuzzy matching, se logró una **alta cobertura y precisión** sin comprometer demasiado el rendimiento.

---

**Conclusión:**  
El flujo final combina **normalización avanzada** y **fuzzy matching optimizado**, logrando un equilibrio entre cobertura, precisión y velocidad de ejecución. Este enfoque permitió aumentar significativamente la cantidad de canciones correctamente etiquetadas con sus géneros y emociones, frente a los métodos iniciales de coincidencia exacta y fuzzy matching con umbrales más altos.

"""

# ============================================
# Normalizar nombres para comparar
# ============================================

import pandas as pd
from rapidfuzz import process, fuzz
import unidecode
import re

# Función de normalización avanzada de nombres
# - Convierte a minúsculas
# - Elimina acentos
# - Elimina texto dentro de paréntesis
# - Reemplaza "&" por "and" y "-" por espacio
# - Unifica colaboraciones con "feat"
# - Elimina espacios extra
def normalize_name(s):
    if not isinstance(s, str):
        return ""
    s = s.lower().strip()
    s = unidecode.unidecode(s)               # eliminar acentos
    s = re.sub(r"\s*\(.*?\)\s*", "", s)     # eliminar paréntesis y contenido
    s = s.replace("&", "and").replace("-", " ")  # uniformar separadores
    s = re.sub(r"feat\.|ft\.", "feat", s)   # uniformar colaboraciones
    s = re.sub(r"\s+", " ", s)              # colapsar espacios
    return s

# Aplicamos normalización a los datasets
df_spotify_youtube['artist_name'] = df_spotify_youtube['Artist'].astype(str).apply(normalize_name)
df_spotify_youtube['track_name']  = df_spotify_youtube['Track'].astype(str).apply(normalize_name)

df_genres['artist_name'] = df_genres['artists'].astype(str).apply(normalize_name)
df_genres['track_name']  = df_genres['track_name'].astype(str).apply(normalize_name)
df_genres = df_genres.rename(columns={'track_genre': 'genre'})
df_genres['genre'] = df_genres['genre'].astype(str).str.strip()  # eliminar espacios al inicio y final

df_emotion['artist_name'] = df_emotion['artist'].astype(str).apply(normalize_name)
df_emotion['track_name']  = df_emotion['track'].astype(str).apply(normalize_name)

print("Nombres normalizados correctamente.\n")

print(f"Filas totales df_spotify_youtube: {len(df_spotify_youtube)}")
print(f"Filas totales df_genres: {len(df_genres)}")
print(f"Filas totales df_emotion: {len(df_emotion)}")

# ============================================
# Crear columnas combinadas (artista + canción)
# ============================================

# Combinamos artista y canción en una sola columna para facilitar comparaciones
df_spotify_youtube['artist_track'] = df_spotify_youtube['artist_name'] + ' - ' + df_spotify_youtube['track_name']
df_genres['artist_track'] = df_genres['artist_name'] + ' - ' + df_genres['track_name']
df_emotion['artist_track'] = df_emotion['artist_name'] + ' - ' + df_emotion['track_name']

# Eliminamos duplicados en los datasets de géneros y emociones
df_genres_unique = df_genres.drop_duplicates(subset=['artist_track'], keep='first').copy()
df_emotion_unique = df_emotion.drop_duplicates(subset=['artist_track'], keep='first').copy()

# ============================================
# Coincidencia difusa optimizada (compatible con rapidfuzz 3.x)
# ============================================

print("Realizando coincidencia aproximada optimizada (umbral 60%)...")

# Función auxiliar: obtenemos la primera letra del artista
# Esto nos ayuda a reducir comparaciones innecesarias
def get_first_letter(s):
    return s[0] if isinstance(s, str) and len(s) > 0 else "_"

df_spotify_youtube['first_letter'] = df_spotify_youtube['artist_name'].apply(get_first_letter)
df_genres_unique['first_letter'] = df_genres_unique['artist_name'].apply(get_first_letter)
df_emotion_unique['first_letter'] = df_emotion_unique['artist_name'].apply(get_first_letter)

# Función de coincidencia difusa rápida
# - Compara cada artista + canción del dataset de Spotify/YouTube con los datasets de género y emoción
# - Solo compara filas que empiezan con la misma letra (optimización)
# - Usa un umbral para decidir si hay coincidencia (por defecto 60%)
def fast_fuzzy_match(df_source, df_target, threshold=60):
    results = []
    for letter in df_source['first_letter'].unique():
        src_subset = df_source[df_source['first_letter'] == letter]
        tgt_subset = df_target[df_target['first_letter'] == letter]
        if tgt_subset.empty:
            results.extend([None] * len(src_subset))
            continue

        # Calcula matriz de similitud usando token_sort_ratio
        score_matrix = process.cdist(
            src_subset['artist_track'].tolist(),
            tgt_subset['artist_track'].tolist(),
            scorer=fuzz.token_sort_ratio,
            workers=-1  # multiproceso
        )

        # Tomamos la mejor coincidencia para cada fila
        best_indices = score_matrix.argmax(axis=1)
        best_scores = score_matrix.max(axis=1)
        matched = [
            tgt_subset.iloc[idx]['artist_track'] if score >= threshold else None
            for idx, score in zip(best_indices, best_scores)
        ]
        results.extend(matched)
    return results

# Ejecutamos coincidencias difusas
df_spotify_youtube = df_spotify_youtube.copy()
df_spotify_youtube['match_genre'] = fast_fuzzy_match(df_spotify_youtube, df_genres_unique, threshold=60)
df_spotify_youtube['match_emotion'] = fast_fuzzy_match(df_spotify_youtube, df_emotion_unique, threshold=60)

# ============================================
# Merge con géneros y emociones
# ============================================

# Hacemos merge de los datos de género basados en la coincidencia difusa
df_merge = pd.merge(
    df_spotify_youtube,
    df_genres_unique[['artist_track', 'genre', 'popularity', 'mode', 'time_signature']],
    left_on='match_genre',
    right_on='artist_track',
    how='left',
    suffixes=('', '_genre')
)

# Hacemos merge de los datos de emoción basados en la coincidencia difusa
df_merge = pd.merge(
    df_merge,
    df_emotion_unique[['artist_track', 'seeds', 'number_of_emotion_tags', 'valence_tags', 'arousal_tags', 'dominance_tags']],
    left_on='match_emotion',
    right_on='artist_track',
    how='left',
    suffixes=('', '_emotion')
)

# Limpiamos columnas innecesarias que quedaron del merge
df_merge = df_merge.drop(columns=['artist_track_genre', 'artist_track_emotion'], errors='ignore')

# Resultados finales
print(f"Filas totales tras merges difusos: {len(df_merge)}")
print(f"Filas con género asignado: {df_merge['genre'].notna().sum()}")
print(f"Filas con datos de emoción asignados: {df_merge['seeds'].notna().sum()}")

# Mostramos las primeras filas
df_merge.head()

"""## Descripción de las columnas del dataset 2 opcion

- **Artist:** Nombre del artista o artistas autores de la canción.
- **Url_spotify:** URL del artista o canción en Spotify.
- **Track:** Nombre de la canción.
- **Album:** Nombre del álbum donde está la canción.
- **Album_type:** Tipo de álbum (`album`, `single`, `compilation`).
- **Uri:** URI de la pista para usar con la API de Spotify.
- **Danceability:** Indica qué tan bailable es la canción (basado en tempo, estabilidad rítmica y fuerza del beat).
- **Energy:** Medida de intensidad y actividad musical; valores cercanos a 1 implican alta energía.

**Campos con nota: no normalizar**
- **Key:** Tonalidad (valores discretos que representan notas).

	| Valor | Nota musical |
	|---:|---|
	| -1 | No detectado |
	| 0 | C (Do) |
	| 1 | C♯ / D♭ |
	| 2 | D (Re) |
	| 3 | D♯ / E♭ |
	| 4 | E (Mi) |
	| 5 | F (Fa) |
	| 6 | F♯ / G♭ |
	| 7 | G (Sol) |
	| 8 | G♯ / A♭ |
	| 9 | A (La) |
	| 10 | A♯ / B♭ |
	| 11 | B (Si) |

- **Loudness:** Sonoridad medida en decibelios (dB).

- **Speechiness:** Detección de contenido hablado en la pista. Interpretación común:
	- **0.66–1.0:** Contenido principalmente hablado (p. ej. podcasts, audiolibros).
	- **0.33–0.66:** Mezcla de música y voz (p. ej. rap con secciones habladas).
	- **0.0–0.33:** Contenido principalmente musical.

- **Acousticness:** Probabilidad de que la pista sea acústica (valores cercanos a 1 indican mayor confianza en que es acústica).
- **Instrumentalness:** Predicción de ausencia de voces; valores cercanos a 1 indican que es instrumental.
- **Liveness:** Indica presencia de audiencia o grabación en directo (valores cercanos a 1 sugieren directo).

- **Valence:** Mide la positividad/agradabilidad (0.0–1.0). Guía de interpretación:
	- **0.7–1.0:** Alta valencia — sonido feliz, enérgico.
	- **0.4–0.7:** Valencia media — neutral o mezclado.
	- **0.0–0.4:** Baja valencia — sonido triste o melancólico.

- **Tempo:** Pulsaciones por minuto (BPM) estimadas.
- **duration_ms:** Duración de la pista en milisegundos.

## Campos de YouTube / métricas sociales

- **Url_youtube:** Enlace al video en YouTube.
- **Title:** Título del video.
- **Channel:** Canal de YouTube del autor/artista.
- **Views, Likes, Comments:** Métricas del video (visitas, 'me gusta', comentarios).
- **Description:** Descripción del video.
- **Licensed:** Indica si el video es contenido licenciado (`true`/`false`).
- **official_video:** Indica si el video es el oficial (`true`/`false`).

- **Stream:** Número de reproducciones en Spotify.

## Campos marcados como redundantes

- **artist_name:** Redundante con `Artist`.
- **track_name:** Redundante con `Track`.
- **artist_track:** Unión de artista y pista; buscable pero redundante.
- **first_letter:** Primera letra del nombre del artista (solo útil para agrupaciones rápidas).
- **match_genre:** Repetición de información de género o `artist_track`.

## Otros campos adicionales
- **genre:** Género musical.
- **popularity:** Popularidad relativa de la pista.
- **mode:** Modalidad musical (`0` menor, `1` mayor).
- **time_signature:** Compás de la canción (p. ej. 3, 4, 5).
- **seeds:** Palabras clave usadas para recolectar la pista.
- **number_of_emotions_tags:** Número de palabras que contribuyeron a la puntuación emocional.
- **valences_tags, arousal_tags, dominance_tags:** Descriptores de dimensiones emocionales (valencia, activación, dominio).

# Transformacion

### 1. Mostrar todas las columnas y previsualizar los datos
Primero configuramos pandas para mostrar **todas las columnas** del DataFrame. Esto es útil para inspeccionar los datos sin que Google Colab las oculte por defecto. Luego usamos `head()` para visualizar las primeras filas y confirmar que las columnas están correctamente cargadas y con los tipos adecuados.

---

### 2. Eliminar columnas que ya no son necesarias
Después del proceso de matching difuso, algunas columnas se vuelven irrelevantes.  
Por ejemplo:
- `match_emotion` y `match_genre` eran columnas temporales con los resultados del matching.
- `Artist`, `track_name` y `first_letter` se usaron solamente durante la normalización, limpieza y optimización.

Eliminamos estas columnas para limpiar el DataFrame y evitar redundancia.

---

### 3. Imputación de valores faltantes en columnas numéricas con KNN
Las columnas numéricas seleccionadas:
- `popularity`
- `mode`
- `time_signature`
- `valence_tags`
- `arousal_tags`
- `dominance_tags`
- `number_of_emotion_tags`

se imputan usando **`KNNImputer`**.

El KNNImputer funciona de la siguiente manera:
- Para cada valor faltante busca **k filas similares** (vecinos).  
- Calcula un valor estimado a partir de los vecinos.  
- Rellena el NaN con esa estimación.

Usamos `n_neighbors=5`, que es un valor equilibrado para evitar tanto sobreajuste como estimaciones demasiado generales.

Este método es más avanzado que usar la media o la moda porque:
- tiene en cuenta relaciones entre variables,  
- conserva patrones reales en los datos,  
- reduce la distorsión estadística.

---

### 4. Imputación avanzada para columnas categóricas
Para las columnas categóricas:
- `genre`  
- `seeds`

aplicamos un enfoque en **dos pasos**:

#### Paso A: Moda por artista
Para cada artista, rellenamos los valores faltantes usando **el valor más frecuente dentro del propio artista**.  
Esto asume que un artista suele tener:
- un mismo género (o muy similar),  
- un perfil emocional parecido.

Si existe moda por artista → se usa ese valor.  
Si no existe (artista con todas las filas vacías) → pasamos al siguiente paso.

#### Paso B: Moda global
Si después del paso anterior aún quedan valores faltantes, los rellenamos con la **moda global** de toda la columna.

Esto asegura que **no quede ningún NaN**, manteniendo coherencia.

---

### 5. Revisión de valores faltantes
Después de imputar:
- mostramos cuántas filas tienen género y seeds asignados,  
- y calculamos cuántos valores faltantes permanecen en el DataFrame.

Esto sirve para validar que:
- la imputación funcionó correctamente,  
- no quedan columnas críticas con NaN,  
- solo quedan NaN en columnas que son opcionales o eliminables.

---

### 6. Normalización de todas las columnas numéricas
Finalmente seleccionamos *todas* las columnas numéricas y aplicamos **`MinMaxScaler`**.

Esta transformación:
- escala todos los valores al rango **0 a 1**,  
- preserva las proporciones internas,  
- evita que columnas con valores muy grandes dominen a las otras.

Esto es importante para modelos de Machine Learning como:
- KNN,  
- Redes Neuronales,  
- SVM,  
- Modelos basados en distancia,  
- Clustering.

---

### Resultado final
Tras ejecutar todo el bloque:

- No quedan valores faltantes en columnas relevantes  
- Los datos están imputados con técnicas avanzadas (KNN + moda por artista)  
- Todas las columnas numéricas están normalizadas  
- El DataFrame queda limpio, homogéneo y listo para modelado
"""

# Configurar pandas para mostrar todas las columnas
pd.set_option('display.max_columns', None)

# Mostrar las primeras filas
df_merge.head()

# Eliminar columnas que no sirven una vez hecho el merge
df_merge.drop(columns=['match_emotion', 'match_genre','Artist', 'track_name', 'first_letter'], inplace=True)

df_merge.shape

# ============================================
# RELLENO DE VALORES FALTANTES
# ============================================
# Columnas numéricas con KNN
num_cols = ['popularity', 'mode', 'time_signature', 'valence_tags', 'arousal_tags', 'dominance_tags', 'number_of_emotion_tags']
imputer = KNNImputer(n_neighbors=5)
df_merge[num_cols] = imputer.fit_transform(df_merge[num_cols])

# Columnas categóricas con moda
cat_cols = ['genre', 'seeds']
for col in cat_cols:
    global_mode = df_merge[col].mode()[0]
    df_merge[col] = df_merge.groupby('artist_name')[col].transform(
        lambda x: x.fillna(x.mode()[0] if not x.mode().empty else global_mode)
    )
    df_merge[col].fillna(global_mode, inplace=True)


print(f"Filas totales tras merges difusos: {len(df_merge)}")
print(f"Filas con género asignado: {df_merge['genre'].notna().sum()}")
print(f"Filas con datos de emoción asignados: {df_merge['seeds'].notna().sum()}")
print(f"Filas con valores nulos restantes: {df_merge.isna().sum().sum()}")

nulls = df_merge.isna().sum()
percent = (df_merge.isna().sum() / len(df_merge)) * 100

df_null_report = pd.DataFrame({
    "nulls": nulls,
    "percent": percent
}).query("nulls > 0").sort_values("percent", ascending=False)

df_null_report

# Seleccionar solo columnas numéricas
# uso de MinMax para normalizar los valores numericos
numeric_cols = df_merge.select_dtypes(include=['float64', 'int64']).columns
min_max_scaler = MinMaxScaler()
df_merge[numeric_cols] = min_max_scaler.fit_transform(df_merge[numeric_cols])